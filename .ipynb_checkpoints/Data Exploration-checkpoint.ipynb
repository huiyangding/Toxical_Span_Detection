{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import inflect\n",
    "import more_itertools as mit\n",
    "p = inflect.engine()\n",
    "\n",
    "wnl = WordNetLemmatizer() # Simple nltk Lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Toxical = pd.read_csv(r\"C:\\Users\\Hamilton\\Desktop\\Semval\\tsd_trial.csv\")\n",
    "SwearWords = pd.read_csv(r\"C:\\Users\\Hamilton\\Desktop\\Semval\\SwearWords.csv\")\n",
    "SwearWordsList = SwearWords['SWEAR'].to_list() #.replace(\"-$\", \"\", regex=True)\n",
    "replacements=[('\\xa0-', ''), ('\\\\\\\\', '')] \n",
    "for pat, repl in replacements:\n",
    "    SwearWordsList1 = list(OrderedDict.fromkeys([stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in SwearWordsList] + [re.sub(pat, repl, i.lower()) for i in SwearWordsList]))\n",
    "# SwearWordsList2 = list(OrderedDict.fromkeys([p.plural(word.lower()) for word in SwearWordsList1] + [p.singular(word.lower()) for word in SwearWordsList1]))\n",
    "SwearWordsList = [w for w in SwearWordsList1 if not w in stop_words]\n",
    "Toxical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkToxicalWords (sampledText, index):\n",
    "    toxicalWords = []\n",
    "    sepCharList = [list(group) for group in mit.consecutive_groups(literal_eval(Toxical.iloc[index][0]))]\n",
    "    charList = []\n",
    "    for word in sepCharList:\n",
    "        charList.append(list(sampledText[int(i)] for i in word)) #Extract character from there\n",
    "#     print(charList)\n",
    "#     print(len(charList))\n",
    "    spanList = [None] * len(charList)\n",
    "#     print(len(spanList))\n",
    "    for i in range(len(charList)):\n",
    "        spanList[i] = str(''.join(charList[i]))\n",
    "#     if ' ' in charList:\n",
    "# #         splitList = [i for i,x in enumerate(charList) if x == ' '] #Get the index of \" \" as splitter list\n",
    "# #         temp = zip(chain([0], splitList), chain(splitList, [None])) #Split the list by \" \"\n",
    "#         res = list(''.join(charList[i : j]) for i, j in temp)\n",
    "#         if len(res) > 0:\n",
    "#             resMod = [res[0]] + [i[1:] for i in res[1:]] #Remove the starting \" \" for the words\n",
    "# #                 print(resMod) \n",
    "#         toxicalWords = resMod\n",
    "#     else:\n",
    "#         toxicalWords = [str(''.join(charList))]\n",
    "#     toxicalWords =  [i for i in toxicalWords] \n",
    "    return spanList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['n', 'u', 't', 's', 'h', 'e', 'l', 'l'], ['p', 'a', 't', 'h', 'e', 't', 'i', 'c']]\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nutshell', 'pathetic']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "# sampledRow = 0\n",
    "sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "\n",
    "checkToxicalWords (sampledText, sampledRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "# sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "def getSwearIndex (sampledText, index):\n",
    "    indexList = []\n",
    "#     sampledTextCleaned = [stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in sampledText]\n",
    "    toxicSpan = []\n",
    "    toxicSpanCleaned = []\n",
    "    toxicSpanCleanedidx = []\n",
    "    for idx, val in enumerate(sampledText.split()):\n",
    "        curWord = re.sub('[ ,.\\'\\\"\\\"?]*$', '', stemmer.stem(wnl.lemmatize(re.sub(pat, repl, val.lower()))))\n",
    "#         print(curWord)\n",
    "        if curWord in SwearWordsList:\n",
    "#             print(curWord)\n",
    "            toxicSpan.append(val)\n",
    "            toxicSpanCleaned.append(curWord)\n",
    "            toxicSpanCleanedidx.append(idx)\n",
    "#     intersection = set(sampledTextCleaned.split()).intersection(SwearWordsList)\n",
    "    toxicalWordsLabeled = checkToxicalWords(sampledText, index)\n",
    "    if len(toxicSpanCleaned) > 0:\n",
    "        for i in toxicSpan: \n",
    "            indexList.append([item for item in range(sampledText.find(i), sampledText.find(i) + len(i))])\n",
    "        indexList = [val for sublist in indexList for val in sublist]\n",
    "    return toxicalWordsLabeled, toxicSpanCleaned, indexList\n",
    "\n",
    "def generateNewColumns (dataFrame):\n",
    "    dataFrame['labeled_toxical_words'] = ''\n",
    "    dataFrame['candidate_toxical_words'] = ''\n",
    "    dataFrame['candidate_span'] = ''\n",
    "    for index, row in dataFrame.iterrows():\n",
    "        row['labeled_toxical_words'], row['candidate_toxical_words'], row['candidate_span'] = getSwearIndex(row['text'].lower(), index)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>textSplit</th>\n",
       "      <th>labeled_toxical_words</th>\n",
       "      <th>candidate_toxical_words</th>\n",
       "      <th>candidate_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "      <td>[Because, he's, a, moron, and, a, bigot., It's...</td>\n",
       "      <td>[moron, bigot]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "      <td>[How, about, we, stop, protecting, idiots, and...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "      <td>[If, people, were, smart,, they, would, Boycot...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "      <td>[Trump, Claimed, that, Russia, will, never, in...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "      <td>[As, long, as, your, willing, to, pay, a, lot,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[8, 9, 10, 11, 12]</td>\n",
       "      <td>Only an idiot would use and believe anything t...</td>\n",
       "      <td>[Only, an, idiot, would, use, and, believe, an...</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[8, 9, 10, 11, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[265, 266, 267, 268, 269, 270, 271, 272, 273, ...</td>\n",
       "      <td>Thanks a lot douchebag. You're the reason the ...</td>\n",
       "      <td>[Thanks, a, lot, douchebag., You're, the, reas...</td>\n",
       "      <td>[o try to turn salem into some kind of new-stu...</td>\n",
       "      <td>[stupid, asshol, stupid, asshol, dumb]</td>\n",
       "      <td>[171, 172, 173, 174, 175, 176, 186, 187, 188, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>kick all the non human criminal illegals out o...</td>\n",
       "      <td>[kick, all, the, non, human, criminal, illegal...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[38, 39, 40, 41, 42, 43]</td>\n",
       "      <td>Because driving under Ontario laws is stupid e...</td>\n",
       "      <td>[Because, driving, under, Ontario, laws, is, s...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[38, 39, 40, 41, 42, 43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[277, 278, 279, 280, 281, 282, 283, 284, 285, ...</td>\n",
       "      <td>You're wrong.  The delay between retirement an...</td>\n",
       "      <td>[You're, wrong., The, delay, between, retireme...</td>\n",
       "      <td>[don't make ignorant statements]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[26, 27, 28, 29, 30]</td>\n",
       "      <td>Billy, are you a complete idiot, being thick h...</td>\n",
       "      <td>[Billy,, are, you, a, complete, idiot,, being,...</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[26, 27, 28, 29, 30, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 5...</td>\n",
       "      <td>Trump said, IN AS MANY WORDS, that Mexicans we...</td>\n",
       "      <td>[Trump, said,, IN, AS, MANY, WORDS,, that, Mex...</td>\n",
       "      <td>[mexicans, rapists, drug dealers]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</td>\n",
       "      <td>He's a psychopath.</td>\n",
       "      <td>[He's, a, psychopath.]</td>\n",
       "      <td>[psychopath]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton should be the last person to say anyth...</td>\n",
       "      <td>[Clinton, should, be, the, last, person, to, s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[23, 24, 25, 26]</td>\n",
       "      <td>People insist on being dumb. No other explanat...</td>\n",
       "      <td>[People, insist, on, being, dumb., No, other, ...</td>\n",
       "      <td>[dumb]</td>\n",
       "      <td>[dumb]</td>\n",
       "      <td>[23, 24, 25, 26, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[]</td>\n",
       "      <td>Canadians killed by Islamic extremists? The im...</td>\n",
       "      <td>[Canadians, killed, by, Islamic, extremists?, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[51, 52, 53, 54, 55, 56, 57, 58, 59]</td>\n",
       "      <td>So next year if you apply for yours, then you'...</td>\n",
       "      <td>[So, next, year, if, you, apply, for, yours,, ...</td>\n",
       "      <td>[hypocrite]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[103, 104, 105, 106, 107, 108, 109, 110, 111, ...</td>\n",
       "      <td>This new has made the A/P, CNBC, Bloomberg,  e...</td>\n",
       "      <td>[This, new, has, made, the, A/P,, CNBC,, Bloom...</td>\n",
       "      <td>[ridiculous]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[31, 32, 33, 34, 35, 36]</td>\n",
       "      <td>Ride those trailer brakes, you morons!</td>\n",
       "      <td>[Ride, those, trailer, brakes,, you, morons!]</td>\n",
       "      <td>[morons]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[37, 38, 39, 40, 41, 42, 43, 44, 45, 139, 140,...</td>\n",
       "      <td>Of course you cannot defend your own hypocrisy...</td>\n",
       "      <td>[Of, course, you, cannot, defend, your, own, h...</td>\n",
       "      <td>[hypocrisy, stupidity]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                spans  \\\n",
       "0            [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                            [29, 30, 31, 32, 33, 34]   \n",
       "2                      [166, 167, 168, 169, 170, 171]   \n",
       "3                            [87, 88, 89, 90, 91, 92]   \n",
       "4                                                  []   \n",
       "5                                  [8, 9, 10, 11, 12]   \n",
       "6   [265, 266, 267, 268, 269, 270, 271, 272, 273, ...   \n",
       "7                                                  []   \n",
       "8                            [38, 39, 40, 41, 42, 43]   \n",
       "9   [277, 278, 279, 280, 281, 282, 283, 284, 285, ...   \n",
       "10                               [26, 27, 28, 29, 30]   \n",
       "11  [35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 5...   \n",
       "12              [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]   \n",
       "13                                                 []   \n",
       "14                                   [23, 24, 25, 26]   \n",
       "15                                                 []   \n",
       "16               [51, 52, 53, 54, 55, 56, 57, 58, 59]   \n",
       "17  [103, 104, 105, 106, 107, 108, 109, 110, 111, ...   \n",
       "18                           [31, 32, 33, 34, 35, 36]   \n",
       "19  [37, 38, 39, 40, 41, 42, 43, 44, 45, 139, 140,...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Because he's a moron and a bigot. It's not any...   \n",
       "1   How about we stop protecting idiots and let na...   \n",
       "2   If people  were  smart, they would  Boycott th...   \n",
       "3   Trump Claimed that Russia will never invade th...   \n",
       "4   As long as your willing to pay a lot more for ...   \n",
       "5   Only an idiot would use and believe anything t...   \n",
       "6   Thanks a lot douchebag. You're the reason the ...   \n",
       "7   kick all the non human criminal illegals out o...   \n",
       "8   Because driving under Ontario laws is stupid e...   \n",
       "9   You're wrong.  The delay between retirement an...   \n",
       "10  Billy, are you a complete idiot, being thick h...   \n",
       "11  Trump said, IN AS MANY WORDS, that Mexicans we...   \n",
       "12                                 He's a psychopath.   \n",
       "13  Clinton should be the last person to say anyth...   \n",
       "14  People insist on being dumb. No other explanat...   \n",
       "15  Canadians killed by Islamic extremists? The im...   \n",
       "16  So next year if you apply for yours, then you'...   \n",
       "17  This new has made the A/P, CNBC, Bloomberg,  e...   \n",
       "18             Ride those trailer brakes, you morons!   \n",
       "19  Of course you cannot defend your own hypocrisy...   \n",
       "\n",
       "                                            textSplit  \\\n",
       "0   [Because, he's, a, moron, and, a, bigot., It's...   \n",
       "1   [How, about, we, stop, protecting, idiots, and...   \n",
       "2   [If, people, were, smart,, they, would, Boycot...   \n",
       "3   [Trump, Claimed, that, Russia, will, never, in...   \n",
       "4   [As, long, as, your, willing, to, pay, a, lot,...   \n",
       "5   [Only, an, idiot, would, use, and, believe, an...   \n",
       "6   [Thanks, a, lot, douchebag., You're, the, reas...   \n",
       "7   [kick, all, the, non, human, criminal, illegal...   \n",
       "8   [Because, driving, under, Ontario, laws, is, s...   \n",
       "9   [You're, wrong., The, delay, between, retireme...   \n",
       "10  [Billy,, are, you, a, complete, idiot,, being,...   \n",
       "11  [Trump, said,, IN, AS, MANY, WORDS,, that, Mex...   \n",
       "12                             [He's, a, psychopath.]   \n",
       "13  [Clinton, should, be, the, last, person, to, s...   \n",
       "14  [People, insist, on, being, dumb., No, other, ...   \n",
       "15  [Canadians, killed, by, Islamic, extremists?, ...   \n",
       "16  [So, next, year, if, you, apply, for, yours,, ...   \n",
       "17  [This, new, has, made, the, A/P,, CNBC,, Bloom...   \n",
       "18      [Ride, those, trailer, brakes,, you, morons!]   \n",
       "19  [Of, course, you, cannot, defend, your, own, h...   \n",
       "\n",
       "                                labeled_toxical_words  \\\n",
       "0                                      [moron, bigot]   \n",
       "1                                            [idiots]   \n",
       "2                                            [idiots]   \n",
       "3                                            [stupid]   \n",
       "4                                                  []   \n",
       "5                                             [idiot]   \n",
       "6   [o try to turn salem into some kind of new-stu...   \n",
       "7                                                  []   \n",
       "8                                            [stupid]   \n",
       "9                    [don't make ignorant statements]   \n",
       "10                                            [idiot]   \n",
       "11                  [mexicans, rapists, drug dealers]   \n",
       "12                                       [psychopath]   \n",
       "13                                                 []   \n",
       "14                                             [dumb]   \n",
       "15                                                 []   \n",
       "16                                        [hypocrite]   \n",
       "17                                       [ridiculous]   \n",
       "18                                           [morons]   \n",
       "19                             [hypocrisy, stupidity]   \n",
       "\n",
       "                   candidate_toxical_words  \\\n",
       "0                                       []   \n",
       "1                                  [idiot]   \n",
       "2                                  [idiot]   \n",
       "3                                 [stupid]   \n",
       "4                                       []   \n",
       "5                                  [idiot]   \n",
       "6   [stupid, asshol, stupid, asshol, dumb]   \n",
       "7                                       []   \n",
       "8                                 [stupid]   \n",
       "9                                       []   \n",
       "10                                 [idiot]   \n",
       "11                                      []   \n",
       "12                                      []   \n",
       "13                                      []   \n",
       "14                                  [dumb]   \n",
       "15                                      []   \n",
       "16                                      []   \n",
       "17                                      []   \n",
       "18                                      []   \n",
       "19                                      []   \n",
       "\n",
       "                                       candidate_span  \n",
       "0                                                  []  \n",
       "1                            [29, 30, 31, 32, 33, 34]  \n",
       "2                      [166, 167, 168, 169, 170, 171]  \n",
       "3                            [87, 88, 89, 90, 91, 92]  \n",
       "4                                                  []  \n",
       "5                                  [8, 9, 10, 11, 12]  \n",
       "6   [171, 172, 173, 174, 175, 176, 186, 187, 188, ...  \n",
       "7                                                  []  \n",
       "8                            [38, 39, 40, 41, 42, 43]  \n",
       "9                                                  []  \n",
       "10                           [26, 27, 28, 29, 30, 31]  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                               [23, 24, 25, 26, 27]  \n",
       "15                                                 []  \n",
       "16                                                 []  \n",
       "17                                                 []  \n",
       "18                                                 []  \n",
       "19                                                 []  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Toxical['textSplit'] = [i.split() for i in Toxical['text']]\n",
    "# ToxicalMatched = generateNewColumns(Toxical.iloc[[685]])\n",
    "ToxicalMatched = generateNewColumns(Toxical)\n",
    "ToxicalMatched.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToxicalMatched[[\"candidate_span\"]].to_csv(\"originalSubmission.txt\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
