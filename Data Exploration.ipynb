{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import inflect\n",
    "import more_itertools as mit\n",
    "import textstat\n",
    "\n",
    "p = inflect.engine()\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Toxical = pd.read_csv(\"tsd_trial.csv\")\n",
    "SwearWords = pd.read_csv(\"SwearWords.csv\")\n",
    "SwearWordsList = SwearWords['SWEAR'].to_list() #.replace(\"-$\", \"\", regex=True)\n",
    "replacements=[('\\xa0-', ''), ('\\\\\\\\', '')] \n",
    "for pat, repl in replacements:\n",
    "    SwearWordsList1 = list(OrderedDict.fromkeys([stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in SwearWordsList] + [re.sub(pat, repl, i.lower()) for i in SwearWordsList]))\n",
    "# SwearWordsList2 = list(OrderedDict.fromkeys([p.plural(word.lower()) for word in SwearWordsList1] + [p.singular(word.lower()) for word in SwearWordsList1]))\n",
    "SwearWordsList = [w for w in SwearWordsList1 if not w in stop_words]\n",
    "Toxical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkToxicalWords (sampledText, index):\n",
    "#     toxicalWords = []\n",
    "#     charList = list(sampledText[int(i)] for i in literal_eval(Toxical.iloc[index][0])) #Extract character from there\n",
    "#     print(charList)\n",
    "#     if ' ' in charList:\n",
    "#         splitList = [i for i,x in enumerate(charList) if x == ' '] #Get the index of \" \" as splitter list\n",
    "#         temp = zip(chain([0], splitList), chain(splitList, [None])) #Split the list by \" \"\n",
    "#         res = list(''.join(charList[i : j]) for i, j in temp)\n",
    "#         print(res)\n",
    "#         if len(res) > 0:\n",
    "#             resMod = [res[0]] + [i[1:] for i in res[1:]] #Remove the starting \" \" for the words\n",
    "# #                 print(resMod) \n",
    "#         toxicalWords = resMod\n",
    "#     else:\n",
    "#         toxicalWords = [str(''.join(charList))]\n",
    "# #     toxicalWords =  [i for i in toxicalWords] \n",
    "#     return toxicalWords\n",
    "\n",
    "def checkToxicalWords (sampledText, index, dataframe):\n",
    "    toxicalWords = []\n",
    "    sepCharList = [list(group) for group in mit.consecutive_groups(literal_eval(dataframe.iloc[index][0]))]\n",
    "    charList = []\n",
    "    for word in sepCharList:\n",
    "        charList.append(list(sampledText[int(i)] for i in word)) #Extract character from there\n",
    "    spanList = [None] * len(charList)\n",
    "    for i in range(len(charList)):\n",
    "        spanList[i] = str(''.join(charList[i]))\n",
    "    return spanList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Trump', 'buffoon', 'disgusting']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "# sampledRow = 0\n",
    "print(sampledRow)\n",
    "sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "\n",
    "checkToxicalWords (sampledText, sampledRow, Toxical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxical['textSplit'] = [i.split() for i in Toxical['text']]\n",
    "# sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "# sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "def getSwearIndex (sampledText, index, dataFrame):\n",
    "    indexList = []\n",
    "#     sampledTextCleaned = [stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in sampledText]\n",
    "    toxicSpan = []\n",
    "    toxicSpanCleaned = []\n",
    "    toxicSpanCleanedidx = []\n",
    "    charCounts = textstat.char_count(sampledText, ignore_spaces = True)  ##Count char counts\n",
    "    senSplit = sampledText.split()\n",
    "    wordCounts = len(senSplit) ## Count word num\n",
    "    for idx, val in enumerate(senSplit):\n",
    "        curWord = re.sub('[ ,.\\'\\\"\\\"?]*$', '', stemmer.stem(wnl.lemmatize(re.sub(pat, repl, val.lower())))) #Stemmer, Encoding to UTF-8, and replace symbols\n",
    "#         print(curWord)\n",
    "        stopwords = [w for w in curWord if w in stop_words] ## Count how many stopwords in the data\n",
    "        if curWord in SwearWordsList:\n",
    "#             print(curWord)\n",
    "            toxicSpan.append(val)\n",
    "            toxicSpanCleaned.append(curWord)\n",
    "            toxicSpanCleanedidx.append(idx)\n",
    "#     intersection = set(sampledTextCleaned.split()).intersection(SwearWordsList)\n",
    "    toxicalWordsLabeled = checkToxicalWords(sampledText, index, dataFrame)\n",
    "    if len(toxicSpanCleaned) > 0:\n",
    "        for i in toxicSpan: \n",
    "            indexList.append([item for item in range(sampledText.find(i), sampledText.find(i) + len(i))])\n",
    "        indexList = [val for sublist in indexList for val in sublist]\n",
    "    return senSplit, toxicalWordsLabeled, toxicSpanCleaned, indexList, wordCounts, charCounts, len(stopwords)\n",
    "\n",
    "def generateNewColumns (dataFrame):\n",
    "    dataFrame['textSplit'] = ''\n",
    "    dataFrame['labeled_toxical_words'] = ''\n",
    "    dataFrame['candidate_toxical_words'] = ''\n",
    "    dataFrame['candidate_span'] = ''\n",
    "    dataFrame['wordCounts'] = ''\n",
    "    dataFrame['charCounts'] = ''\n",
    "    dataFrame['stopCounts'] = ''\n",
    "    \n",
    "    for index, row in dataFrame.iterrows():\n",
    "        row['textSplit'], row['labeled_toxical_words'], row['candidate_toxical_words'], row['candidate_span'], row['wordCounts'], row['charCounts'], row['stopCounts'] = getSwearIndex(row['text'].lower(), index, dataFrame)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>textSplit</th>\n",
       "      <th>labeled_toxical_words</th>\n",
       "      <th>candidate_toxical_words</th>\n",
       "      <th>candidate_span</th>\n",
       "      <th>wordCounts</th>\n",
       "      <th>charCounts</th>\n",
       "      <th>stopCounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "      <td>[because, he's, a, moron, and, a, bigot., it's...</td>\n",
       "      <td>[moron, bigot]</td>\n",
       "      <td>[moron, bigot]</td>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31, 32]</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "      <td>[how, about, we, stop, protecting, idiots, and...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "      <td>[if, people, were, smart,, they, would, boycot...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>29</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "      <td>[trump, claimed, that, russia, will, never, in...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>19</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "      <td>[as, long, as, your, willing, to, pay, a, lot,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hypocrit]</td>\n",
       "      <td>[188, 189, 190, 191, 192, 193, 194, 195, 196, ...</td>\n",
       "      <td>42</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[129, 130, 131, 132, 133, 134]</td>\n",
       "      <td>But ... Trump's not bluffing. He's prepared to...</td>\n",
       "      <td>[but, ..., trump's, not, bluffing., he's, prep...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[129, 130, 131, 132, 133, 134, 135]</td>\n",
       "      <td>30</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>[126, 127, 128, 129, 130, 131]</td>\n",
       "      <td>Can't believe the limited knowledge of this Ar...</td>\n",
       "      <td>[can't, believe, the, limited, knowledge, of, ...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[126, 127, 128, 129, 130, 131, 132]</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>I think it conservative idiots who cannot reac...</td>\n",
       "      <td>[i, think, it, conservative, idiots, who, cann...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>You're an id*ot...Go away.</td>\n",
       "      <td>[you're, an, id*ot...go, away.]</td>\n",
       "      <td>[you're an id*ot]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>Unless there is wording in the employment cont...</td>\n",
       "      <td>[unless, there, is, wording, in, the, employme...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>67</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 spans  \\\n",
       "0             [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                             [29, 30, 31, 32, 33, 34]   \n",
       "2                       [166, 167, 168, 169, 170, 171]   \n",
       "3                             [87, 88, 89, 90, 91, 92]   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "685                     [129, 130, 131, 132, 133, 134]   \n",
       "686                     [126, 127, 128, 129, 130, 131]   \n",
       "687                           [24, 25, 26, 27, 28, 29]   \n",
       "688  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "689                     [136, 137, 138, 139, 140, 141]   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Because he's a moron and a bigot. It's not any...   \n",
       "1    How about we stop protecting idiots and let na...   \n",
       "2    If people  were  smart, they would  Boycott th...   \n",
       "3    Trump Claimed that Russia will never invade th...   \n",
       "4    As long as your willing to pay a lot more for ...   \n",
       "..                                                 ...   \n",
       "685  But ... Trump's not bluffing. He's prepared to...   \n",
       "686  Can't believe the limited knowledge of this Ar...   \n",
       "687  I think it conservative idiots who cannot reac...   \n",
       "688                         You're an id*ot...Go away.   \n",
       "689  Unless there is wording in the employment cont...   \n",
       "\n",
       "                                             textSplit labeled_toxical_words  \\\n",
       "0    [because, he's, a, moron, and, a, bigot., it's...        [moron, bigot]   \n",
       "1    [how, about, we, stop, protecting, idiots, and...              [idiots]   \n",
       "2    [if, people, were, smart,, they, would, boycot...              [idiots]   \n",
       "3    [trump, claimed, that, russia, will, never, in...              [stupid]   \n",
       "4    [as, long, as, your, willing, to, pay, a, lot,...                    []   \n",
       "..                                                 ...                   ...   \n",
       "685  [but, ..., trump's, not, bluffing., he's, prep...              [stupid]   \n",
       "686  [can't, believe, the, limited, knowledge, of, ...              [stupid]   \n",
       "687  [i, think, it, conservative, idiots, who, cann...              [idiots]   \n",
       "688                    [you're, an, id*ot...go, away.]     [you're an id*ot]   \n",
       "689  [unless, there, is, wording, in, the, employme...              [stupid]   \n",
       "\n",
       "    candidate_toxical_words  \\\n",
       "0            [moron, bigot]   \n",
       "1                   [idiot]   \n",
       "2                   [idiot]   \n",
       "3                  [stupid]   \n",
       "4                [hypocrit]   \n",
       "..                      ...   \n",
       "685                [stupid]   \n",
       "686                [stupid]   \n",
       "687                 [idiot]   \n",
       "688                      []   \n",
       "689                [stupid]   \n",
       "\n",
       "                                        candidate_span wordCounts charCounts  \\\n",
       "0         [15, 16, 17, 18, 19, 27, 28, 29, 30, 31, 32]         14         61   \n",
       "1                             [29, 30, 31, 32, 33, 34]         26        115   \n",
       "2                       [166, 167, 168, 169, 170, 171]         29        136   \n",
       "3                             [87, 88, 89, 90, 91, 92]         19         90   \n",
       "4    [188, 189, 190, 191, 192, 193, 194, 195, 196, ...         42        169   \n",
       "..                                                 ...        ...        ...   \n",
       "685                [129, 130, 131, 132, 133, 134, 135]         30        136   \n",
       "686                [126, 127, 128, 129, 130, 131, 132]         21        111   \n",
       "687                           [24, 25, 26, 27, 28, 29]         10         53   \n",
       "688                                                 []          4         23   \n",
       "689                     [136, 137, 138, 139, 140, 141]         67        308   \n",
       "\n",
       "    stopCounts  \n",
       "0            3  \n",
       "1            4  \n",
       "2            2  \n",
       "3            0  \n",
       "4            1  \n",
       "..         ...  \n",
       "685          0  \n",
       "686          4  \n",
       "687          5  \n",
       "688          3  \n",
       "689          1  \n",
       "\n",
       "[690 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToxicalMatched = generateNewColumns(Toxical)\n",
    "ToxicalMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToxicalMatched[[\"candidate_span\"]].to_csv(\"originalSubmission.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training_Trail Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailData = pd.read_csv(\"tsd_trial.csv\")\n",
    "trainingData = pd.read_csv(\"tsd_train.csv\")\n",
    "dataFrames = [trailData, trainingData]\n",
    "toxicDF = pd.concat(dataFrames).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is (8629, 2).\n",
      "\n",
      "Null values:\n",
      "spans    0\n",
      "text     0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The shape of data is %s.\\n\" % str(toxicDF.shape))\n",
    "print(\"Null values:\")\n",
    "print(toxicDF.isnull().sum())\n",
    "print(\"\\n\")\n",
    "toxicDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of SwearWords List\n",
    "SwearWordsList = SwearWords['SWEAR'].to_list() #.replace(\"-$\", \"\", regex=True)\n",
    "replacements=[('\\xa0-', ''), ('\\\\\\\\', '')] \n",
    "for pat, repl in replacements:\n",
    "    SwearWordsList1 = list(OrderedDict.fromkeys([stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in SwearWordsList] + [re.sub(pat, repl, i.lower()) for i in SwearWordsList]))\n",
    "SwearWordsList = [w for w in SwearWordsList1 if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToxicalMatched = generateNewColumns(toxicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailDF = toxicDF[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in trailDF.iterrows():\n",
    "#     row['charCount'] = textstat.char_count(row['text'], ignore_spaces = True)\n",
    "#     row['wordCount'] = len(row['text'].split())\n",
    "# #     for lineNo, line in enumerate(row['text']):\n",
    "# #         print(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "ToxicalMatched = generateNewColumns(trailDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>textSplit</th>\n",
       "      <th>labeled_toxical_words</th>\n",
       "      <th>candidate_toxical_words</th>\n",
       "      <th>candidate_span</th>\n",
       "      <th>wordCounts</th>\n",
       "      <th>charCounts</th>\n",
       "      <th>stopCounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 2...</td>\n",
       "      <td>Lots of so-called Christian suckers. The same ...</td>\n",
       "      <td>[lots, of, so-called, christian, suckers., the...</td>\n",
       "      <td>[christian suckers, lies, fools, fool]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>40</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>[157, 158, 159, 160]</td>\n",
       "      <td>But, but, Trudeau is a feminists,  nand his ca...</td>\n",
       "      <td>[but,, but,, trudeau, is, a, feminists,, nand,...</td>\n",
       "      <td>[fool]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>31</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>[]</td>\n",
       "      <td>Moron-eau is in over his head.  Home Capital i...</td>\n",
       "      <td>[moron-eau, is, in, over, his, head., home, ca...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[132, 133, 134, 135, 136]</td>\n",
       "      <td>28</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>[362, 363, 364, 365, 366, 367, 368, 369, 370, ...</td>\n",
       "      <td>In one of my career choices, I had to make reg...</td>\n",
       "      <td>[in, one, of, my, career, choices,, i, had, to...</td>\n",
       "      <td>[liars, damned liars]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63</td>\n",
       "      <td>337</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>[44, 45, 46, 47, 48, 49, 67, 68, 69, 70, 71]</td>\n",
       "      <td>Perhaps we need a referendum take classify \"st...</td>\n",
       "      <td>[perhaps, we, need, a, referendum, take, class...</td>\n",
       "      <td>[stupid, class]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>[15, 16, 17, 18]</td>\n",
       "      <td>Passing on the crap cards that were dealt you ...</td>\n",
       "      <td>[passing, on, the, crap, cards, that, were, de...</td>\n",
       "      <td>[crap]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>32</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>[853, 854, 855, 856]</td>\n",
       "      <td>The treatment of the Rohingya Muslims in Myanm...</td>\n",
       "      <td>[the, treatment, of, the, rohingya, muslims, i...</td>\n",
       "      <td>[rape]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>165</td>\n",
       "      <td>794</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>[84, 85, 86, 87, 88, 89]</td>\n",
       "      <td>What is it with women that they will tolerate ...</td>\n",
       "      <td>[what, is, it, with, women, that, they, will, ...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[84, 85, 86, 87, 88, 89]</td>\n",
       "      <td>27</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>Tell me, are there other non-contributors that...</td>\n",
       "      <td>[tell, me,, are, there, other, non-contributor...</td>\n",
       "      <td>[tell me, are there other non-contributors tha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>101</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>[19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n",
       "      <td>LOL...love it when stupidity exposes itself on...</td>\n",
       "      <td>[lol...love, it, when, stupidity, exposes, its...</td>\n",
       "      <td>[stupidity]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>[475, 476, 477, 478, 479, 480]</td>\n",
       "      <td>What they really need to do is fix the skyrock...</td>\n",
       "      <td>[what, they, really, need, to, do, is, fix, th...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[475, 476, 477, 478, 479, 480]</td>\n",
       "      <td>107</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>[13, 14, 15, 16, 17, 18, 19, 20, 21, 22]</td>\n",
       "      <td>Libtards are hypocrites.</td>\n",
       "      <td>[libtards, are, hypocrites.]</td>\n",
       "      <td>[hypocrites]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>[]</td>\n",
       "      <td>\"may have\"? ...and you want to know why americ...</td>\n",
       "      <td>[\"may, have\"?, ...and, you, want, to, know, wh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>138</td>\n",
       "      <td>640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>[59, 60, 61, 62, 63, 64]</td>\n",
       "      <td>Another completely idiotic from one of the bar...</td>\n",
       "      <td>[another, completely, idiotic, from, one, of, ...</td>\n",
       "      <td>[trolls]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[19, 20, 21, 22, 23, 24, 25]</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>[200, 201, 202, 203, 204, 205]</td>\n",
       "      <td>\"Yet you are posting here.\\nHilarious!\"\\n~ ~ ~...</td>\n",
       "      <td>[\"yet, you, are, posting, here., hilarious!\", ...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[200, 201, 202, 203, 204, 205, 206]</td>\n",
       "      <td>42</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>[80, 81, 82, 83, 84]</td>\n",
       "      <td>Oh, of course.  Anything that truthfully repor...</td>\n",
       "      <td>[oh,, of, course., anything, that, truthfully,...</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[80, 81, 82, 83, 84]</td>\n",
       "      <td>90</td>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>[28, 29, 30, 31, 32, 33]</td>\n",
       "      <td>LOLOLOL... of all the silly things you have ev...</td>\n",
       "      <td>[lololol..., of, all, the, silly, things, you,...</td>\n",
       "      <td>[things]</td>\n",
       "      <td>[silli]</td>\n",
       "      <td>[22, 23, 24, 25, 26]</td>\n",
       "      <td>33</td>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>[45, 46, 47, 48, 49, 50]</td>\n",
       "      <td>Obama didn't lie. It's just that some really s...</td>\n",
       "      <td>[obama, didn't, lie., it's, just, that, some, ...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[45, 46, 47, 48, 49, 50]</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>[25, 26, 27, 28, 29]</td>\n",
       "      <td>another arrogant liberal troll living in the h...</td>\n",
       "      <td>[another, arrogant, liberal, troll, living, in...</td>\n",
       "      <td>[troll]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>[17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 2...</td>\n",
       "      <td>Unless you are a drunken idiot, it is nearly i...</td>\n",
       "      <td>[unless, you, are, a, drunken, idiot,, it, is,...</td>\n",
       "      <td>[drunken idiot]</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>[25, 26, 27, 28, 29, 30]</td>\n",
       "      <td>42</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "4876  [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 2...   \n",
       "4877                               [157, 158, 159, 160]   \n",
       "4878                                                 []   \n",
       "4879  [362, 363, 364, 365, 366, 367, 368, 369, 370, ...   \n",
       "4880       [44, 45, 46, 47, 48, 49, 67, 68, 69, 70, 71]   \n",
       "4881                                   [15, 16, 17, 18]   \n",
       "4882                               [853, 854, 855, 856]   \n",
       "4883                           [84, 85, 86, 87, 88, 89]   \n",
       "4884  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4885               [19, 20, 21, 22, 23, 24, 25, 26, 27]   \n",
       "4886                     [475, 476, 477, 478, 479, 480]   \n",
       "4887           [13, 14, 15, 16, 17, 18, 19, 20, 21, 22]   \n",
       "4888                                                 []   \n",
       "4889                           [59, 60, 61, 62, 63, 64]   \n",
       "4890                     [200, 201, 202, 203, 204, 205]   \n",
       "4891                               [80, 81, 82, 83, 84]   \n",
       "4892                           [28, 29, 30, 31, 32, 33]   \n",
       "4893                           [45, 46, 47, 48, 49, 50]   \n",
       "4894                               [25, 26, 27, 28, 29]   \n",
       "4895  [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 2...   \n",
       "\n",
       "                                                   text  \\\n",
       "4876  Lots of so-called Christian suckers. The same ...   \n",
       "4877  But, but, Trudeau is a feminists,  nand his ca...   \n",
       "4878  Moron-eau is in over his head.  Home Capital i...   \n",
       "4879  In one of my career choices, I had to make reg...   \n",
       "4880  Perhaps we need a referendum take classify \"st...   \n",
       "4881  Passing on the crap cards that were dealt you ...   \n",
       "4882  The treatment of the Rohingya Muslims in Myanm...   \n",
       "4883  What is it with women that they will tolerate ...   \n",
       "4884  Tell me, are there other non-contributors that...   \n",
       "4885  LOL...love it when stupidity exposes itself on...   \n",
       "4886  What they really need to do is fix the skyrock...   \n",
       "4887                           Libtards are hypocrites.   \n",
       "4888  \"may have\"? ...and you want to know why americ...   \n",
       "4889  Another completely idiotic from one of the bar...   \n",
       "4890  \"Yet you are posting here.\\nHilarious!\"\\n~ ~ ~...   \n",
       "4891  Oh, of course.  Anything that truthfully repor...   \n",
       "4892  LOLOLOL... of all the silly things you have ev...   \n",
       "4893  Obama didn't lie. It's just that some really s...   \n",
       "4894  another arrogant liberal troll living in the h...   \n",
       "4895  Unless you are a drunken idiot, it is nearly i...   \n",
       "\n",
       "                                              textSplit  \\\n",
       "4876  [lots, of, so-called, christian, suckers., the...   \n",
       "4877  [but,, but,, trudeau, is, a, feminists,, nand,...   \n",
       "4878  [moron-eau, is, in, over, his, head., home, ca...   \n",
       "4879  [in, one, of, my, career, choices,, i, had, to...   \n",
       "4880  [perhaps, we, need, a, referendum, take, class...   \n",
       "4881  [passing, on, the, crap, cards, that, were, de...   \n",
       "4882  [the, treatment, of, the, rohingya, muslims, i...   \n",
       "4883  [what, is, it, with, women, that, they, will, ...   \n",
       "4884  [tell, me,, are, there, other, non-contributor...   \n",
       "4885  [lol...love, it, when, stupidity, exposes, its...   \n",
       "4886  [what, they, really, need, to, do, is, fix, th...   \n",
       "4887                       [libtards, are, hypocrites.]   \n",
       "4888  [\"may, have\"?, ...and, you, want, to, know, wh...   \n",
       "4889  [another, completely, idiotic, from, one, of, ...   \n",
       "4890  [\"yet, you, are, posting, here., hilarious!\", ...   \n",
       "4891  [oh,, of, course., anything, that, truthfully,...   \n",
       "4892  [lololol..., of, all, the, silly, things, you,...   \n",
       "4893  [obama, didn't, lie., it's, just, that, some, ...   \n",
       "4894  [another, arrogant, liberal, troll, living, in...   \n",
       "4895  [unless, you, are, a, drunken, idiot,, it, is,...   \n",
       "\n",
       "                                  labeled_toxical_words  \\\n",
       "4876             [christian suckers, lies, fools, fool]   \n",
       "4877                                             [fool]   \n",
       "4878                                                 []   \n",
       "4879                              [liars, damned liars]   \n",
       "4880                                    [stupid, class]   \n",
       "4881                                             [crap]   \n",
       "4882                                             [rape]   \n",
       "4883                                           [stupid]   \n",
       "4884  [tell me, are there other non-contributors tha...   \n",
       "4885                                        [stupidity]   \n",
       "4886                                           [idiots]   \n",
       "4887                                       [hypocrites]   \n",
       "4888                                                 []   \n",
       "4889                                           [trolls]   \n",
       "4890                                           [stupid]   \n",
       "4891                                            [idiot]   \n",
       "4892                                           [things]   \n",
       "4893                                           [stupid]   \n",
       "4894                                            [troll]   \n",
       "4895                                    [drunken idiot]   \n",
       "\n",
       "     candidate_toxical_words                        candidate_span wordCounts  \\\n",
       "4876                      []                                    []         40   \n",
       "4877                      []                                    []         31   \n",
       "4878                 [idiot]             [132, 133, 134, 135, 136]         28   \n",
       "4879                      []                                    []         63   \n",
       "4880                      []                                    []         22   \n",
       "4881                      []                                    []         32   \n",
       "4882                      []                                    []        165   \n",
       "4883                [stupid]              [84, 85, 86, 87, 88, 89]         27   \n",
       "4884                      []                                    []        101   \n",
       "4885                [stupid]  [19, 20, 21, 22, 23, 24, 25, 26, 27]          9   \n",
       "4886                 [idiot]        [475, 476, 477, 478, 479, 480]        107   \n",
       "4887                      []                                    []          3   \n",
       "4888                      []                                    []        138   \n",
       "4889                 [idiot]          [19, 20, 21, 22, 23, 24, 25]         10   \n",
       "4890                [stupid]   [200, 201, 202, 203, 204, 205, 206]         42   \n",
       "4891                 [idiot]                  [80, 81, 82, 83, 84]         90   \n",
       "4892                 [silli]                  [22, 23, 24, 25, 26]         33   \n",
       "4893                [stupid]              [45, 46, 47, 48, 49, 50]         13   \n",
       "4894                      []                                    []         13   \n",
       "4895                 [idiot]              [25, 26, 27, 28, 29, 30]         42   \n",
       "\n",
       "     charCounts stopCounts  \n",
       "4876        183          3  \n",
       "4877        132          2  \n",
       "4878        124          0  \n",
       "4879        337          9  \n",
       "4880        115          4  \n",
       "4881        159          2  \n",
       "4882        794          3  \n",
       "4883        113          2  \n",
       "4884        546          1  \n",
       "4885         52          3  \n",
       "4886        486          1  \n",
       "4887         22          5  \n",
       "4888        640          2  \n",
       "4889         57          3  \n",
       "4890        177          0  \n",
       "4891        443          3  \n",
       "4892        148          5  \n",
       "4893         62          3  \n",
       "4894         64          3  \n",
       "4895        171          2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToxicalMatched.iloc[4876 : 4896, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordCounts     34.440\n",
       "charCounts    162.503\n",
       "stopCounts      2.906\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToxicalMatched.iloc[ : , -3 : ].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordCounts     33.800812\n",
       "charCounts    159.213199\n",
       "stopCounts      2.160980\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToxicalMatched.iloc[ : , -3 : ].std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordLimit = ToxicalMatched.iloc[ : , -3 : ].mean(axis = 0)[0] + ToxicalMatched.iloc[ : , -3 : ].std(axis = 0)[0]\n",
    "int(wordLimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamilton\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Perpective_Score</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ds0n31r</td>\n",
       "      <td>0.897231</td>\n",
       "      <td>1</td>\n",
       "      <td>I personally just don\\u2019t like the way it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ds0n31v</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ds0n31v</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ds0n31w</td>\n",
       "      <td>0.084523</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>ds0n31x</td>\n",
       "      <td>0.214329</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  Perpective_Score  toxicity  \\\n",
       "0           0  ds0n31r          0.897231         1   \n",
       "1           1  ds0n31v          0.044559         0   \n",
       "2           2  ds0n31v          0.044559         0   \n",
       "3          14  ds0n31w          0.084523         0   \n",
       "4          27  ds0n31x          0.214329         0   \n",
       "\n",
       "                                                body  \n",
       "0  I personally just don\\u2019t like the way it l...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC_2018_01_Text_Combined = pd.read_csv(\"RC_2018_01_Text_Combined.csv\")\n",
    "RC_2018_01_Text_Combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_2018_01_Text_Combined_Not_Null = RC_2018_01_Text_Combined[RC_2018_01_Text_Combined.body.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Perpective_Score</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ds0n31r</td>\n",
       "      <td>0.897231</td>\n",
       "      <td>1</td>\n",
       "      <td>I personally just don\\u2019t like the way it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ds0n31v</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ds0n31v</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ds0n31w</td>\n",
       "      <td>0.084523</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>ds0n31x</td>\n",
       "      <td>0.214329</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>ds0n31x</td>\n",
       "      <td>0.214329</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>ds0n31y</td>\n",
       "      <td>0.715958</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53</td>\n",
       "      <td>ds0n31z</td>\n",
       "      <td>0.280021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>ds0n31z</td>\n",
       "      <td>0.280021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>ds0n320</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  Perpective_Score  toxicity  \\\n",
       "0           0  ds0n31r          0.897231         1   \n",
       "1           1  ds0n31v          0.044559         0   \n",
       "2           2  ds0n31v          0.044559         0   \n",
       "3          14  ds0n31w          0.084523         0   \n",
       "4          27  ds0n31x          0.214329         0   \n",
       "5          37  ds0n31x          0.214329         0   \n",
       "6          40  ds0n31y          0.715958         1   \n",
       "7          53  ds0n31z          0.280021         0   \n",
       "8          55  ds0n31z          0.280021         0   \n",
       "9          66  ds0n320          0.178349         0   \n",
       "\n",
       "                                                body  \n",
       "0  I personally just don\\u2019t like the way it l...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC_2018_01_Text_Combined.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
