{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Toxical = pd.read_csv(\"tsd_trial.csv\")\n",
    "SwearWords = pd.read_csv(\"SwearWords.csv\")\n",
    "SwearWordsList = SwearWords['SWEAR'].to_list() #.replace(\"-$\", \"\", regex=True)\n",
    "replacements=[('\\xa0-', ''), ('\\\\\\\\', '')] \n",
    "for pat, repl in replacements:\n",
    "    SwearWordsList1 = list(OrderedDict.fromkeys([stemmer.stem(wnl.lemmatize(re.sub(pat, repl, i.lower()))) for i in SwearWordsList] + [re.sub(pat, repl, i.lower()) for i in SwearWordsList]))\n",
    "# SwearWordsList2 = list(OrderedDict.fromkeys([p.plural(word.lower()) for word in SwearWordsList1] + [p.singular(word.lower()) for word in SwearWordsList1]))\n",
    "SwearWordsList = [w for w in SwearWordsList1 if not w in stop_words]\n",
    "Toxical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkToxicalWords (sampledText, index):\n",
    "    toxicalWords = []\n",
    "    charList = list(sampledText[int(i)] for i in literal_eval(Toxical.iloc[index][0])) #Extract character from there\n",
    "    if ' ' in charList:\n",
    "        splitList = [i for i,x in enumerate(charList) if x == ' '] #Get the index of \" \" as splitter list\n",
    "        temp = zip(chain([0], splitList), chain(splitList, [None])) #Split the list by \" \"\n",
    "        res = list(''.join(charList[i : j]) for i, j in temp)\n",
    "        if len(res) > 0:\n",
    "            resMod = [res[0]] + [i[1:] for i in res[1:]] #Remove the starting \" \" for the words\n",
    "#                 print(resMod) \n",
    "        toxicalWords = resMod\n",
    "    else:\n",
    "        toxicalWords = [str(''.join(charList))]\n",
    "#     toxicalWords =  [i for i in toxicalWords] \n",
    "    return toxicalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['idiots']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "sampledRow = 2\n",
    "sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "\n",
    "checkToxicalWords (sampledText, sampledRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Toxical['textSplit'] = [i.split() for i in Toxical['text']]\n",
    "# sampledRow = random.randint(0, len(Toxical) - 1) #Sample a random row\n",
    "# sampledText = Toxical.iloc[sampledRow][1] #Extract document text from that row\n",
    "def getSwearIndex (sampledText, index):\n",
    "    indexList = []\n",
    "    intersection = set(sampledText.split()).intersection(SwearWordsList)\n",
    "    toxicalWordsLabeled = checkToxicalWords (sampledText, index)\n",
    "    toxicalWordsDetect = list(intersection)\n",
    "    if len(intersection) > 0:\n",
    "        for i in intersection: \n",
    "            indexList.append([item for item in range(sampledText.find(i), sampledText.find(i) + len(i))])\n",
    "        indexList = [val for sublist in indexList for val in sublist]\n",
    "    return toxicalWordsLabeled, toxicalWordsDetect, indexList\n",
    "\n",
    "def generateNewColumns (dataFrame):\n",
    "    dataFrame['labeled_toxical_words'] = ''\n",
    "    dataFrame['candidate_toxical_words'] = ''\n",
    "    dataFrame['candidate_span'] = ''\n",
    "    for index, row in dataFrame.iterrows():\n",
    "        row['labeled_toxical_words'], row['candidate_toxical_words'], row['candidate_span'] = getSwearIndex(row['text'].lower(), index)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>textSplit</th>\n",
       "      <th>labeled_toxical_words</th>\n",
       "      <th>candidate_toxical_words</th>\n",
       "      <th>candidate_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "      <td>[Because, he's, a, moron, and, a, bigot., It's...</td>\n",
       "      <td>[moronbigot]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "      <td>[How, about, we, stop, protecting, idiots, and...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "      <td>[If, people, were, smart,, they, would, Boycot...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "      <td>[Trump, Claimed, that, Russia, will, never, in...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "      <td>[As, long, as, your, willing, to, pay, a, lot,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[129, 130, 131, 132, 133, 134]</td>\n",
       "      <td>But ... Trump's not bluffing. He's prepared to...</td>\n",
       "      <td>[But, ..., Trump's, not, bluffing., He's, prep...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>[126, 127, 128, 129, 130, 131]</td>\n",
       "      <td>Can't believe the limited knowledge of this Ar...</td>\n",
       "      <td>[Can't, believe, the, limited, knowledge, of, ...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>I think it conservative idiots who cannot reac...</td>\n",
       "      <td>[I, think, it, conservative, idiots, who, cann...</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>You're an id*ot...Go away.</td>\n",
       "      <td>[You're, an, id*ot...Go, away.]</td>\n",
       "      <td>[you're, an, id*ot]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>Unless there is wording in the employment cont...</td>\n",
       "      <td>[Unless, there, is, wording, in, the, employme...</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 spans  \\\n",
       "0             [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                             [29, 30, 31, 32, 33, 34]   \n",
       "2                       [166, 167, 168, 169, 170, 171]   \n",
       "3                             [87, 88, 89, 90, 91, 92]   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "685                     [129, 130, 131, 132, 133, 134]   \n",
       "686                     [126, 127, 128, 129, 130, 131]   \n",
       "687                           [24, 25, 26, 27, 28, 29]   \n",
       "688  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "689                     [136, 137, 138, 139, 140, 141]   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Because he's a moron and a bigot. It's not any...   \n",
       "1    How about we stop protecting idiots and let na...   \n",
       "2    If people  were  smart, they would  Boycott th...   \n",
       "3    Trump Claimed that Russia will never invade th...   \n",
       "4    As long as your willing to pay a lot more for ...   \n",
       "..                                                 ...   \n",
       "685  But ... Trump's not bluffing. He's prepared to...   \n",
       "686  Can't believe the limited knowledge of this Ar...   \n",
       "687  I think it conservative idiots who cannot reac...   \n",
       "688                         You're an id*ot...Go away.   \n",
       "689  Unless there is wording in the employment cont...   \n",
       "\n",
       "                                             textSplit labeled_toxical_words  \\\n",
       "0    [Because, he's, a, moron, and, a, bigot., It's...          [moronbigot]   \n",
       "1    [How, about, we, stop, protecting, idiots, and...              [idiots]   \n",
       "2    [If, people, were, smart,, they, would, Boycot...              [idiots]   \n",
       "3    [Trump, Claimed, that, Russia, will, never, in...              [stupid]   \n",
       "4    [As, long, as, your, willing, to, pay, a, lot,...                    []   \n",
       "..                                                 ...                   ...   \n",
       "685  [But, ..., Trump's, not, bluffing., He's, prep...              [stupid]   \n",
       "686  [Can't, believe, the, limited, knowledge, of, ...              [stupid]   \n",
       "687  [I, think, it, conservative, idiots, who, cann...              [idiots]   \n",
       "688                    [You're, an, id*ot...Go, away.]   [you're, an, id*ot]   \n",
       "689  [Unless, there, is, wording, in, the, employme...              [stupid]   \n",
       "\n",
       "    candidate_toxical_words                  candidate_span  \n",
       "0                        []                              []  \n",
       "1                        []                              []  \n",
       "2                        []                              []  \n",
       "3                  [stupid]        [87, 88, 89, 90, 91, 92]  \n",
       "4                        []                              []  \n",
       "..                      ...                             ...  \n",
       "685                      []                              []  \n",
       "686                      []                              []  \n",
       "687                      []                              []  \n",
       "688                      []                              []  \n",
       "689                [stupid]  [136, 137, 138, 139, 140, 141]  \n",
       "\n",
       "[690 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToxicalMatched = generateNewColumns(Toxical)\n",
    "ToxicalMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToxicalMatched[[\"candidate_span\"]].to_csv(\"originalSubmission.txt\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
